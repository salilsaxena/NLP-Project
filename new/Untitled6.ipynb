{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lNRGNPaWR_9n"
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import reuters\n",
    "# from nltk import bigrams, trigrams\n",
    "import numpy as np \n",
    "# import pandas as pd\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, GRU, Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import re\n",
    "# from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fdhAR6-kPPsl"
   },
   "outputs": [],
   "source": [
    "text = open('shakespeare.txt', 'r').read().lower()[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq8kvr0EPQ2B",
    "outputId": "2e0cf5a2-4ab5-457b-b78e-8c0af6ffafe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 59970\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(text):\n",
    "    length = 30\n",
    "    sequences = []\n",
    "    for i in range(length, len(text)):\n",
    "        seq = text[i-length:i+1]\n",
    "        sequences.append(seq)\n",
    "    print(\"Total Sequences: {}\".format(len(sequences)))\n",
    "    return sequences\n",
    "sequences = create_sequences(text)\n",
    "# print(sequences[0])\n",
    "chars = sorted(list(set(text)))\n",
    "mapping = dict((c,i) for i,c in enumerate(chars))\n",
    "def encode_seq(seq):\n",
    "    sequences = []\n",
    "    for line in seq: \n",
    "        encoded_seq = [mapping[char] for char in line]\n",
    "        sequences.append(encoded_seq)\n",
    "#     print(encode_seq)\n",
    "    return sequences\n",
    "sequences = encode_seq(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4iHxxx49Pwt4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vocab = len(mapping)\n",
    "sequences = np.asarray(sequences)\n",
    "\n",
    "X, y= sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(X,y,test_size = 0.1, random_state = 49) # for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQOifeqdSRG1",
    "outputId": "c2725e77-97a6-4f19-8c43-768324d77531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 30, 50)            1800      \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 150)               90900     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 36)                5436      \n",
      "=================================================================\n",
      "Total params: 98,136\n",
      "Trainable params: 98,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1687/1687 [==============================] - 184s 109ms/step - loss: 2.4038 - acc: 0.3045 - val_loss: 2.1732 - val_acc: 0.3573\n",
      "Epoch 2/100\n",
      "1687/1687 [==============================] - 182s 108ms/step - loss: 2.0811 - acc: 0.3865 - val_loss: 2.0037 - val_acc: 0.4080\n",
      "Epoch 3/100\n",
      "1687/1687 [==============================] - 184s 109ms/step - loss: 1.9464 - acc: 0.4205 - val_loss: 1.8862 - val_acc: 0.4477\n",
      "Epoch 4/100\n",
      "1687/1687 [==============================] - 182s 108ms/step - loss: 1.8548 - acc: 0.4451 - val_loss: 1.8310 - val_acc: 0.4577\n",
      "Epoch 5/100\n",
      "1687/1687 [==============================] - 178s 106ms/step - loss: 1.7904 - acc: 0.4617 - val_loss: 1.7898 - val_acc: 0.4677\n",
      "Epoch 6/100\n",
      "1687/1687 [==============================] - 183s 109ms/step - loss: 1.7386 - acc: 0.4772 - val_loss: 1.7583 - val_acc: 0.4771\n",
      "Epoch 7/100\n",
      "1687/1687 [==============================] - 184s 109ms/step - loss: 1.6955 - acc: 0.4861 - val_loss: 1.7408 - val_acc: 0.4767\n",
      "Epoch 8/100\n",
      "1687/1687 [==============================] - 187s 111ms/step - loss: 1.6632 - acc: 0.4927 - val_loss: 1.7344 - val_acc: 0.4809\n",
      "Epoch 9/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.6366 - acc: 0.4997 - val_loss: 1.7162 - val_acc: 0.4934\n",
      "Epoch 10/100\n",
      "1687/1687 [==============================] - 185s 110ms/step - loss: 1.6128 - acc: 0.5042 - val_loss: 1.7064 - val_acc: 0.4919\n",
      "Epoch 11/100\n",
      "1687/1687 [==============================] - 185s 109ms/step - loss: 1.5924 - acc: 0.5096 - val_loss: 1.7119 - val_acc: 0.4892\n",
      "Epoch 12/100\n",
      "1687/1687 [==============================] - 183s 108ms/step - loss: 1.5768 - acc: 0.5133 - val_loss: 1.7033 - val_acc: 0.4954\n",
      "Epoch 13/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.5621 - acc: 0.5170 - val_loss: 1.7139 - val_acc: 0.4929\n",
      "Epoch 14/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.5445 - acc: 0.5252 - val_loss: 1.7004 - val_acc: 0.4967\n",
      "Epoch 15/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.5341 - acc: 0.5234 - val_loss: 1.7140 - val_acc: 0.4949\n",
      "Epoch 16/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.5232 - acc: 0.5292 - val_loss: 1.7123 - val_acc: 0.4914\n",
      "Epoch 17/100\n",
      "1687/1687 [==============================] - 185s 110ms/step - loss: 1.5151 - acc: 0.5287 - val_loss: 1.7114 - val_acc: 0.4944\n",
      "Epoch 18/100\n",
      "1687/1687 [==============================] - 187s 111ms/step - loss: 1.5049 - acc: 0.5324 - val_loss: 1.7096 - val_acc: 0.4957\n",
      "Epoch 19/100\n",
      "1687/1687 [==============================] - 185s 110ms/step - loss: 1.4951 - acc: 0.5351 - val_loss: 1.7071 - val_acc: 0.4957\n",
      "Epoch 20/100\n",
      "1687/1687 [==============================] - 179s 106ms/step - loss: 1.4889 - acc: 0.5365 - val_loss: 1.6979 - val_acc: 0.5024\n",
      "Epoch 21/100\n",
      "1687/1687 [==============================] - 180s 107ms/step - loss: 1.4875 - acc: 0.5352 - val_loss: 1.7064 - val_acc: 0.4992\n",
      "Epoch 22/100\n",
      "1687/1687 [==============================] - 179s 106ms/step - loss: 1.4775 - acc: 0.5374 - val_loss: 1.7150 - val_acc: 0.4964\n",
      "Epoch 23/100\n",
      "1687/1687 [==============================] - 179s 106ms/step - loss: 1.4762 - acc: 0.5390 - val_loss: 1.7033 - val_acc: 0.4989\n",
      "Epoch 24/100\n",
      "1687/1687 [==============================] - 178s 105ms/step - loss: 1.4677 - acc: 0.5389 - val_loss: 1.7127 - val_acc: 0.4952\n",
      "Epoch 25/100\n",
      "1687/1687 [==============================] - 176s 105ms/step - loss: 1.4616 - acc: 0.5437 - val_loss: 1.7116 - val_acc: 0.4961\n",
      "Epoch 26/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4584 - acc: 0.5418 - val_loss: 1.7113 - val_acc: 0.5023\n",
      "Epoch 27/100\n",
      "1687/1687 [==============================] - 177s 105ms/step - loss: 1.4548 - acc: 0.5429 - val_loss: 1.7073 - val_acc: 0.5044\n",
      "Epoch 28/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4527 - acc: 0.5435 - val_loss: 1.7154 - val_acc: 0.4972\n",
      "Epoch 29/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4490 - acc: 0.5456 - val_loss: 1.7096 - val_acc: 0.4981\n",
      "Epoch 30/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4462 - acc: 0.5448 - val_loss: 1.7154 - val_acc: 0.4959\n",
      "Epoch 31/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4419 - acc: 0.5466 - val_loss: 1.7282 - val_acc: 0.4992\n",
      "Epoch 32/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4403 - acc: 0.5464 - val_loss: 1.7106 - val_acc: 0.5036\n",
      "Epoch 33/100\n",
      "1687/1687 [==============================] - 174s 103ms/step - loss: 1.4350 - acc: 0.5502 - val_loss: 1.7193 - val_acc: 0.5026\n",
      "Epoch 34/100\n",
      "1687/1687 [==============================] - 175s 104ms/step - loss: 1.4331 - acc: 0.5477 - val_loss: 1.7197 - val_acc: 0.5029\n",
      "Epoch 35/100\n",
      "1687/1687 [==============================] - 178s 105ms/step - loss: 1.4324 - acc: 0.5473 - val_loss: 1.7211 - val_acc: 0.5016\n",
      "Epoch 36/100\n",
      "1687/1687 [==============================] - 181s 108ms/step - loss: 1.4277 - acc: 0.5494 - val_loss: 1.7184 - val_acc: 0.5001\n",
      "Epoch 37/100\n",
      "1687/1687 [==============================] - 180s 107ms/step - loss: 1.4239 - acc: 0.5519 - val_loss: 1.7119 - val_acc: 0.4976\n",
      "Epoch 38/100\n",
      "1687/1687 [==============================] - 179s 106ms/step - loss: 1.4189 - acc: 0.5526 - val_loss: 1.7199 - val_acc: 0.5033\n",
      "Epoch 39/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4188 - acc: 0.5513 - val_loss: 1.7259 - val_acc: 0.5028\n",
      "Epoch 40/100\n",
      "1687/1687 [==============================] - 173s 103ms/step - loss: 1.4200 - acc: 0.5525 - val_loss: 1.7374 - val_acc: 0.4997\n",
      "Epoch 41/100\n",
      "1687/1687 [==============================] - 174s 103ms/step - loss: 1.4156 - acc: 0.5548 - val_loss: 1.7263 - val_acc: 0.5026\n",
      "Epoch 42/100\n",
      "1687/1687 [==============================] - 174s 103ms/step - loss: 1.4098 - acc: 0.5538 - val_loss: 1.7291 - val_acc: 0.5023\n",
      "Epoch 43/100\n",
      "1687/1687 [==============================] - 176s 104ms/step - loss: 1.4145 - acc: 0.5553 - val_loss: 1.7277 - val_acc: 0.5009\n",
      "Epoch 44/100\n",
      "1687/1687 [==============================] - 175s 104ms/step - loss: 1.4173 - acc: 0.5509 - val_loss: 1.7182 - val_acc: 0.5004\n",
      "Epoch 45/100\n",
      "1687/1687 [==============================] - 174s 103ms/step - loss: 1.4070 - acc: 0.5536 - val_loss: 1.7322 - val_acc: 0.5011\n",
      "Epoch 46/100\n",
      "1687/1687 [==============================] - 173s 102ms/step - loss: 1.4055 - acc: 0.5566 - val_loss: 1.7258 - val_acc: 0.4976\n",
      "Epoch 47/100\n",
      "1687/1687 [==============================] - 173s 102ms/step - loss: 1.4092 - acc: 0.5549 - val_loss: 1.7342 - val_acc: 0.5001\n",
      "Epoch 48/100\n",
      "1687/1687 [==============================] - 171s 102ms/step - loss: 1.4057 - acc: 0.5579 - val_loss: 1.7277 - val_acc: 0.4991\n",
      "Epoch 49/100\n",
      "1687/1687 [==============================] - 173s 102ms/step - loss: 1.3994 - acc: 0.5591 - val_loss: 1.7220 - val_acc: 0.5024\n",
      "Epoch 50/100\n",
      "1687/1687 [==============================] - 172s 102ms/step - loss: 1.3995 - acc: 0.5583 - val_loss: 1.7329 - val_acc: 0.5043\n",
      "Epoch 51/100\n",
      "1687/1687 [==============================] - 172s 102ms/step - loss: 1.4019 - acc: 0.5559 - val_loss: 1.7289 - val_acc: 0.4992\n",
      "Epoch 52/100\n",
      "1687/1687 [==============================] - 172s 102ms/step - loss: 1.3990 - acc: 0.5579 - val_loss: 1.7277 - val_acc: 0.5033\n",
      "Epoch 53/100\n",
      "1687/1687 [==============================] - 172s 102ms/step - loss: 1.3988 - acc: 0.5558 - val_loss: 1.7251 - val_acc: 0.5034\n",
      "Epoch 54/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3995 - acc: 0.5542 - val_loss: 1.7314 - val_acc: 0.4986\n",
      "Epoch 55/100\n",
      "1687/1687 [==============================] - 171s 101ms/step - loss: 1.3949 - acc: 0.5587 - val_loss: 1.7332 - val_acc: 0.5043\n",
      "Epoch 56/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3971 - acc: 0.5575 - val_loss: 1.7334 - val_acc: 0.5003\n",
      "Epoch 57/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3882 - acc: 0.5598 - val_loss: 1.7332 - val_acc: 0.5054\n",
      "Epoch 58/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3925 - acc: 0.5598 - val_loss: 1.7321 - val_acc: 0.5044\n",
      "Epoch 59/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3915 - acc: 0.5603 - val_loss: 1.7270 - val_acc: 0.5034\n",
      "Epoch 60/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3917 - acc: 0.5591 - val_loss: 1.7357 - val_acc: 0.5013\n",
      "Epoch 61/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3884 - acc: 0.5587 - val_loss: 1.7257 - val_acc: 0.5048\n",
      "Epoch 62/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3886 - acc: 0.5611 - val_loss: 1.7347 - val_acc: 0.5051\n",
      "Epoch 63/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3883 - acc: 0.5590 - val_loss: 1.7287 - val_acc: 0.5018\n",
      "Epoch 64/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3874 - acc: 0.5615 - val_loss: 1.7313 - val_acc: 0.4996\n",
      "Epoch 65/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3853 - acc: 0.5607 - val_loss: 1.7279 - val_acc: 0.5043\n",
      "Epoch 66/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3841 - acc: 0.5598 - val_loss: 1.7324 - val_acc: 0.5006\n",
      "Epoch 67/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3805 - acc: 0.5616 - val_loss: 1.7521 - val_acc: 0.4999\n",
      "Epoch 68/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3783 - acc: 0.5618 - val_loss: 1.7347 - val_acc: 0.5036\n",
      "Epoch 69/100\n",
      "1687/1687 [==============================] - 167s 99ms/step - loss: 1.3819 - acc: 0.5598 - val_loss: 1.7317 - val_acc: 0.4959\n",
      "Epoch 70/100\n",
      "1687/1687 [==============================] - 166s 98ms/step - loss: 1.3781 - acc: 0.5620 - val_loss: 1.7440 - val_acc: 0.5049\n",
      "Epoch 71/100\n",
      "1687/1687 [==============================] - 167s 99ms/step - loss: 1.3827 - acc: 0.5615 - val_loss: 1.7315 - val_acc: 0.5008\n",
      "Epoch 72/100\n",
      "1687/1687 [==============================] - 167s 99ms/step - loss: 1.3819 - acc: 0.5623 - val_loss: 1.7387 - val_acc: 0.5006\n",
      "Epoch 73/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3754 - acc: 0.5616 - val_loss: 1.7428 - val_acc: 0.5041\n",
      "Epoch 74/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3763 - acc: 0.5626 - val_loss: 1.7313 - val_acc: 0.5028\n",
      "Epoch 75/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3774 - acc: 0.5602 - val_loss: 1.7295 - val_acc: 0.5026\n",
      "Epoch 76/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3731 - acc: 0.5639 - val_loss: 1.7356 - val_acc: 0.5016\n",
      "Epoch 77/100\n",
      "1687/1687 [==============================] - 167s 99ms/step - loss: 1.3779 - acc: 0.5617 - val_loss: 1.7482 - val_acc: 0.4992\n",
      "Epoch 78/100\n",
      "1687/1687 [==============================] - 168s 99ms/step - loss: 1.3739 - acc: 0.5645 - val_loss: 1.7373 - val_acc: 0.4977\n",
      "Epoch 79/100\n",
      "1687/1687 [==============================] - 167s 99ms/step - loss: 1.3724 - acc: 0.5630 - val_loss: 1.7436 - val_acc: 0.5018\n",
      "Epoch 80/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3704 - acc: 0.5631 - val_loss: 1.7483 - val_acc: 0.5028\n",
      "Epoch 81/100\n",
      "1687/1687 [==============================] - 168s 100ms/step - loss: 1.3740 - acc: 0.5633 - val_loss: 1.7416 - val_acc: 0.5014\n",
      "Epoch 82/100\n",
      "1687/1687 [==============================] - 168s 99ms/step - loss: 1.3700 - acc: 0.5635 - val_loss: 1.7444 - val_acc: 0.4999\n",
      "Epoch 83/100\n",
      "1687/1687 [==============================] - 169s 100ms/step - loss: 1.3749 - acc: 0.5624 - val_loss: 1.7366 - val_acc: 0.5023\n",
      "Epoch 84/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3710 - acc: 0.5623 - val_loss: 1.7437 - val_acc: 0.5048\n",
      "Epoch 85/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3726 - acc: 0.5619 - val_loss: 1.7532 - val_acc: 0.5009\n",
      "Epoch 86/100\n",
      "1687/1687 [==============================] - 174s 103ms/step - loss: 1.3693 - acc: 0.5651 - val_loss: 1.7397 - val_acc: 0.5071\n",
      "Epoch 87/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.3706 - acc: 0.5625 - val_loss: 1.7386 - val_acc: 0.4997\n",
      "Epoch 88/100\n",
      "1687/1687 [==============================] - 186s 111ms/step - loss: 1.3668 - acc: 0.5649 - val_loss: 1.7457 - val_acc: 0.5054\n",
      "Epoch 89/100\n",
      "1687/1687 [==============================] - 186s 110ms/step - loss: 1.3705 - acc: 0.5658 - val_loss: 1.7429 - val_acc: 0.5051\n",
      "Epoch 90/100\n",
      "1687/1687 [==============================] - 179s 106ms/step - loss: 1.3668 - acc: 0.5655 - val_loss: 1.7592 - val_acc: 0.4987\n",
      "Epoch 91/100\n",
      "1687/1687 [==============================] - 174s 103ms/step - loss: 1.3707 - acc: 0.5632 - val_loss: 1.7497 - val_acc: 0.5058\n",
      "Epoch 92/100\n",
      "1687/1687 [==============================] - 172s 102ms/step - loss: 1.3677 - acc: 0.5628 - val_loss: 1.7492 - val_acc: 0.5019\n",
      "Epoch 93/100\n",
      "1687/1687 [==============================] - 171s 101ms/step - loss: 1.3709 - acc: 0.5639 - val_loss: 1.7376 - val_acc: 0.5024\n",
      "Epoch 94/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3654 - acc: 0.5649 - val_loss: 1.7438 - val_acc: 0.5029\n",
      "Epoch 95/100\n",
      "1687/1687 [==============================] - 171s 101ms/step - loss: 1.3692 - acc: 0.5632 - val_loss: 1.7442 - val_acc: 0.5011\n",
      "Epoch 96/100\n",
      "1687/1687 [==============================] - 172s 102ms/step - loss: 1.3631 - acc: 0.5653 - val_loss: 1.7536 - val_acc: 0.5021\n",
      "Epoch 97/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3582 - acc: 0.5667 - val_loss: 1.7408 - val_acc: 0.5013\n",
      "Epoch 98/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3638 - acc: 0.5667 - val_loss: 1.7432 - val_acc: 0.5063\n",
      "Epoch 99/100\n",
      "1687/1687 [==============================] - 168s 99ms/step - loss: 1.3618 - acc: 0.5680 - val_loss: 1.7461 - val_acc: 0.5046\n",
      "Epoch 100/100\n",
      "1687/1687 [==============================] - 170s 101ms/step - loss: 1.3601 - acc: 0.5650 - val_loss: 1.7508 - val_acc: 0.5041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6397733e10>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab, 50, input_length=30, trainable=True))\n",
    "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
    "model.add(Dense(vocab, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "# fit the model\n",
    "model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXpWayxpXnW5",
    "outputId": "51776d20-dc91-45c7-d507-bc83f17b2ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# model.save('/content/drive/MyDrive/NLP')\n",
    "reconstructed_model = keras.models.load_model(\"/NLP\")\n",
    "# reconstructed_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RZCqXeE2SS3t"
   },
   "outputs": [],
   "source": [
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of characters\n",
    "\tfor _ in range(n_chars):\n",
    "\t\t# encode the characters as integers\n",
    "\t\tencoded = [mapping[char] for char in in_text]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict character\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# reverse map integer to character\n",
    "\t\tout_char = ''\n",
    "\t\tfor char, index in mapping.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_char = char\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += char\n",
    "\treturn in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkQsvKYdVOSD",
    "outputId": "517275b1-3f56-4f93-b306-360306a424ec"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b8dd5645643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreconstructed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NLP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mapping' is not defined"
     ]
    }
   ],
   "source": [
    "inp = 'a'\n",
    "reconstructed_model = keras.models.load_model(\"NLP\")\n",
    "print(generate_seq(reconstructed_model, mapping, 30, inp.lower(),30)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfiA7TdFVr1M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kBcuWMiWVTZ",
    "outputId": "ef1f34af-12c8-4662-aa42-8168b3dac08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "351Znf0QWXAX"
   },
   "outputs": [],
   "source": [
    "!cd drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-as_EyayWgfg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_KY-riHWlD_"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8X1v4RTXeWh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
